---
title: "Surface Detection by Robot Movements"
author: "Marian Dumitrascu"
date: "March 19, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

For this project I choosed a Kaggle.com open competion project. This is [*CareerCon 2019 - Help Navigate Robots*](https://www.kaggle.com/c/career-con-2019). Here is the description of the project from Kaggle:


> *In this competition, you’ll help robots recognize the floor surface they’re standing on using data collected from Inertial Measurement Units (IMU sensors).*
> *We’ve collected IMU sensor data while driving a small mobile robot over different floor surfaces on the university premises. The task is to predict which one of the nine floor types (carpet, tiles, concrete) the  robot is on using sensor data such as acceleration and velocity. Succeed and you'll help improve the navigation of robots without assistance across many different surfaces, so they won’t fall down on the job.*

The task is challenging, but I believe I can obtain a decent result using techniques and tools learned in this course.

## Report Structure

1. First I will describe data provided and the output expected
2. Then, will perform data analysis, visualization and get insights
3. pre-process and transform data
4. decide the model to use, measure its performance and tune it
5. perform the final data prediction and show the results, submit to Kaggle
6. draw some conclusions

## Report and Data Location

I also keep this project on GitHub here: https://github.com/mariandumitrascu/ph125_9_HelpRobotsNavigate
Data loaded by the R scripts is kept on an AWS public S3 bucket, to bee easily loaded. This will bee available for the duration of grading.

# Data Description

Input data from Kaggle consists in 4 files:

* *X_trian.csv* and *X_test.csv* -  the input data, covering 10 sensor channels and 128 measurements per time series plus three ID columns:

	+ *row_id*: The ID for this row.
	+ *series_id*: ID number for the measurement series. Foreign key to y_train/sample_submission.
	+ *measurement_number*: Measurement number within the series.

	The orientation channels encode the current angles how the robot is oriented as a quaternion (see Wikipedia). Angular velocity describes the angle and speed of motion, and linear acceleration components describe how the speed is changing at different times. The 10 sensor channels are:

	+ *orientation_X*
	+ *orientation_Y*
	+ *orientation_Z*
	+ *orientation_W*
	+ *angular_velocity_X*
	+ *angular_velocity_Y*
	+ *angular_velocity_Z*
	+ *linear_acceleration_X*
	+ *linear_acceleration_Y*
	+ *linear_acceleration_Z*

* *y_train.csv* - the surfaces for training set.

	+ *series_id*: ID number for the measurement series.
	+ *group_id*: ID number for all of the measurements taken in a recording session. Provided for the training set only, to enable more cross validation strategies.
	+ *surface*: lables or classes of the training data. this is the element that need to be predicted

* *sample_submission.csv* - a sample submission file in the correct format.

In this report I will split the training data into two partitions, will fit a model on the first one, and measure it's accuracy on the second. I will also use a small part of data to make it run faster. The R script for generating the final resuls will use all data. 

# Data Analysis

I will make the following assumptions about observations:

* all observations are made using the same robot
* the interval between the 128 observations for each seeries is always the same. 
* the surface is a plane, no stairs, hills or valleys

From a physicyst perspective there are thre forces involved: gravitation force, robot propulsion force, and friction force. Gravitation force is constant. Friction force depends on the surface by a coefficient and propulsion is an unknown variable. We need to basically determine the friction coeficient based on a movement pattern. Moving objects will travel longer if the surface has a lower friction than on a surface with higher friction. On the other side, changing direction can be teeper on a surface with higher friction. 


## First Insights

```{r load packages, include=FALSE}
options(repos="https://CRAN.R-project.org")
# install.packages("ISLR")
# install.packages("orientlib")
# install.packages("RSpincalc")
# devtools::install_github("collectivemedia/tictoc")
# install.packages("kableExtra")
# install.packages("doParallel", dependencies = TRUE)
# install.packages("randomForest", dependencies = TRUE)
# install.packages("rf")

library(tidyverse)
library(readr)
library(ISLR)
library(caret)
library(orientlib)
library(matrixStats)
library(randomForest)
library(RSpincalc)
library(tictoc)

```


```{r load data, include=FALSE, cache=TRUE}

# load X_train.csv and y_train.csv 
# x_train <- read_csv("https://s3.amazonaws.com/terraform-bucket-dq001/X_train.csv", col_names = TRUE)
# y_train <- read_csv("https://s3.amazonaws.com/terraform-bucket-dq001/y_train.csv", col_names = TRUE)
# x_test <- read_csv("https://s3.amazonaws.com/terraform-bucket-dq001/X_test.csv", col_names = TRUE)

x_train <- read_csv("data/X_train.csv")
y_train <- read_csv("data/y_train.csv")
x_test <- read_csv("data/x_test.csv")

# then join them
x_train <- x_train %>% inner_join(y_train, by = "series_id")
# convert surface to factor
x_train <- mutate(x_train, surface = as.factor(surface))

nicetable <- head(x_train, 5) %>% knitr::kable()
```
Here is quick look at the first 5 rows of the training data: `r nicetable`

## Data Distribution

```{r include=FALSE}
dist <- x_train %>% group_by(surface) %>% 
	summarize(measurements = n_distinct(series_id))

nicetable <- dist %>% knitr::kable()

```
Here is a distributon of measurements by surface in the training set: `r nicetable`

Angular velocity is produced by a magnetostatic sensor, it indicates the angular speed the robot is movig in reference with earth orientation. Here is the distribution of angular velocity by surface:

```{r warning=FALSE}
options(repr.plot.width = 6, repr.plot.height = 4, repr.plot.res = 100)

x_train %>%
    gather(key = "feature", value = "value", 4:13 ) %>%
    filter(feature %in% c('angular_velocity_X', 
    											'angular_velocity_Y' ,
    											'angular_velocity_Z')) %>%  
    ggplot(aes(x = value, fill=surface)) + 
    geom_density() +
    facet_grid(surface ~ feature) + 
    xlim(-0.5, 0.5)
```
Linear acceleration is produced by an inertial sensor. We can approximate this later with linear distacne if we consider the the unit of time to be 1. Here is the distribution of linear acceleration by surface:

```{r warning=FALSE}
options(repr.plot.width = 6, repr.plot.height = 4, repr.plot.res = 100)

x_train %>%
    gather(key = "feature", value = "value", 4:13 ) %>%
    filter(feature %in% c('linear_acceleration_X' ,
    											'linear_acceleration_Y', 
    											'linear_acceleration_Z')) %>%  
    ggplot(aes(x = value, fill=surface)) + 
    geom_density() +
    facet_grid(surface ~ feature) + 
    xlim(-15, 5)

```
We can observe noticeable differences in distribution of these variables by surface. 

To do the same for orientation we'll need to convert quaternion values to euler angles which are more intuitive and easier to interpret. Euler angles provide a way to represent the 3D orientation of an object using a combination of three rotations about different axes: roll (*phi*), pitch (*theta*) and yaw (*psi*)

```{r fig.height=2, fig.width=3, message=FALSE, warning=FALSE, include=FALSE, cache=TRUE}
download.file(url = "http://www.chrobotics.com/wp-content/uploads/2012/11/Inertial-Frame-1024x655.png",
          destfile = "image_euler_angles.png",
          mode = 'wb')
# knitr::include_graphics(path = "image_euler_angles.png")
```

![Euler Angles](image_euler_angles.png)

This data comes from a gyroscop sensor, it idicates the orientation of the robot. I noted euler anles with: *phi*, *theta* and *psi.* Although we dont know the order of them in our case, they have the following meaning:
 
I used *Q2EA* function in *orientlib* package.(See: https://www.rdocumentation.org/packages/orientlib/versions/0.10.3)

```{r quaternions to euler, warning=FALSE}

# define a function to convert quaternion values to euler angles. 
convert_quaternions_to_euler <- function(a_dataset){
	
	# use Q2EA from RSpincalc to convert quaternions to euler angles
	Q <- a_dataset %>% select(orientation_X, 
														orientation_Y, 
														orientation_Z, 
														orientation_W) %>% 
		as.matrix()
	
	euler_matrix <- Q2EA(Q, EulerOrder='xyz', 
											 tol = 10 * .Machine$double.eps, 
											 ichk = FALSE, 
											 ignoreAllChk = FALSE)

	# add the new columns to the dataset
	a_dataset <- a_dataset %>% mutate(phi = euler_matrix[,1],
																		theta = euler_matrix[,2], 
																		psi = euler_matrix[,3])
	
	# remove quaternion columns
	a_dataset <- a_dataset %>% select(-orientation_X, 
																		-orientation_Y,  
																		-orientation_Z, 
																		-orientation_W)
	
	# return the new dataset
	a_dataset
}

x_train <- convert_quaternions_to_euler(x_train)
x_test <- convert_quaternions_to_euler(x_test)
```


```{r warning=FALSE}
options(repr.plot.width = 6, repr.plot.height = 4, repr.plot.res = 100)

x_train %>%
    gather(key = "feature", value = "value", phi, theta, psi) %>%
    filter(feature %in% c('phi', 
    											'theta' ,
    											'psi')) %>%  
    ggplot(aes(x = value, fill=surface)) + 
    geom_density() +
    facet_grid(surface ~ feature) + 
	xlim(-0.5, 0.5) +
	ylim(0, 0.5)
```
We can see distinct patterns here.


# Data Pre-Processing

## Quaternion to Euler

## More Data Analysis


# Fit The Model

## One-vs-One or One-vs-All

# Results and Submit the Data

# Conclusion

One of the most important outcome of this prroject is that I learned a few things in addition to what was presented in the course. 

# Reference

1. Applied Predictive Modeling - Max Kuhn, Kjell Johnson

2. Q2EA: Convert from rotation Quaternions to Euler Angles. Q2EA converts from Quaternions (Q) to Euler Angles (EA) based on D. M. Henderson (1977). Q2EA.Xiao is the algorithm by J. Xiao (2013) for the Princeton Vision Toolkit. https://rdrr.io/cran/RSpincalc/man/Q2EA.html

3. Understanding Quaternions. http://www.chrobotics.com/library/understanding-quaternions

4. Understanding Euler Angles. http://www.chrobotics.com/library/understanding-euler-angles

5. Tune Machine Learning Algorithms in R (random forest case study) by Jason Brownlee. https://machinelearningmastery.com/tune-machine-learning-algorithms-in-r/

6. Classification with more than two classes, from Introduction to Information Retrieval, Christopher D. Manning, Prabhakar Raghavan and Hinrich Schütze,, Cambridge University Press 2008  https://nlp.stanford.edu/IR-book/html/htmledition/classification-with-more-than-two-classes-1.html

7. A Guide To using IMU (Accelerometer and Gyroscope Devices) in Embedded Applications - http://www.starlino.com/imu_guide.html

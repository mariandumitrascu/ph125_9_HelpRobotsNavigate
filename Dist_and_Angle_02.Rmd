---
title: "Surface Detection by Robot Movements"
author: "Marian Dumitrascu"
date: "March 19, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Surface Detection by Robot Movements


## Introduction

gyros, accelerometer and magnetometer sensor

## Data Analysis

You can include R code in the document as follows:

```{r data load, message=FALSE, warning=FALSE}
# install.packages("ISLR")
# install.packages("orientlib")
# install.packages("RSpincalc")
# devtools::install_github("collectivemedia/tictoc")
# install.packages("kableExtra")
library(readr)
library(tidyverse)
library(ISLR)
library(caret)
library(orientlib)
library(matrixStats)
library(randomForest)
library(RSpincalc)
library(tictoc)
library(kableExtra)

x_train <- read_csv("data/X_train.csv")
y_train <- read_csv("data/y_train.csv")
x_test <- read_csv("data/x_test.csv")
```
```{r}

# nrow(x_test)/128

```


```{r data analysis}

# join the labels with the training data set
train_set <- x_train %>% left_join(y_train, by = "series_id")
train_df <- as.data.frame(train_set)
test_df <- as.data.frame(x_test)

train_df <- mutate(train_df, surface = as.factor(surface)) %>% 
	select(-group_id)

```

```{r}

convert_quaternions_to_euler <- function(a_dataset){
	
	# use Q2EA from RSpincalc to convert quaternions to euler angles
	Q <- a_dataset %>% select(orientation_X, orientation_Y, orientation_Z, orientation_W) %>% as.matrix()
	
	euler_matrix <- Q2EA(Q, EulerOrder='xyz', tol = 10 * .Machine$double.eps, ichk = FALSE, ignoreAllChk = FALSE)

	# add the new columns to the dataset
	a_dataset <- a_dataset %>% mutate(phi = euler_matrix[,1], theta = euler_matrix[,2], psi = euler_matrix[,3])
	
	# remove quaternion columns
	a_dataset <- a_dataset %>% select(-orientation_X, -orientation_Y,  -orientation_Z, -orientation_W)
	
	# return the new dataset
	a_dataset
}

train_df <- convert_quaternions_to_euler(train_df)
test_df <- convert_quaternions_to_euler(test_df)


```



```{r}
# function for prreprocessing 
# n_of_rows defaults to total number ofseries
# is_train indicates that the data is training, thus will do an extra action
pre_process <- function(a_dataframe, n_of_rows = nrow(a_dataframe)/128 ) {
	
	# get data grouped by seeries_id and compute some means 
	processed_data_df <- a_dataframe %>% 
	group_by(series_id) %>% 
	summarize(
		phi_mean_all = mean(phi),
		phi_sd_all = sd(phi),
		phi_mean_to_sd_all = mean(phi)/sd(phi),
		theta_mean_all = mean(theta),
		theta_sd_all = sd(theta),
		theta_mean_to_sd_all = mean(theta)/sd(theta),
		psi_mean_all = mean(psi),
		psi_sd_all = sd(psi),
		psi_mean_to_sd_all = mean(psi)/sd(psi)
		) %>% 
		slice(1:n_of_rows)
	
	# define an empty data frame with summary metrics that we'll use for each set of 128 observations
	metrics <- c("dist_total","dist_max","dist_min","dist_max_to_min","dist_mean","dist_sd","dist_mean_to_sd",
							 "omega_total","omega_max","omega_min","omega_max_to_min","omega_mean","omega_sd","omega_mean_to_sd",
							 "phi_total","phi_max","phi_min","phi_mean","phi_sd","phi_mean_to_sd",
							 "theta_total","theta_max","theta_min","theta_mean","theta_sd","theta_mean_to_sd",
							 "psi_total","psi_max","psi_min","psi_mean","psi_sd","psi_mean_to_sd",
							 "euler_total","euler_max","euler_min","euler_mean","euler_sd","euler_mean_to_sd")
	tmp_df <- data.frame(matrix(ncol = length(metrics), nrow = 0) )
	colnames(tmp_df) <- metrics

	# loop over each series
	# should use apply type of function here, but I use "for" until I master the apply
	for (s_id in processed_data_df$series_id)
	{
		# get current measurement set
		this_chunk_df <- a_dataframe %>% filter(series_id == s_id)
		
		# select only columns we are interested in 
		this_chunk_df <- this_chunk_df %>% 
			select(
			phi, theta, psi,  
			angular_velocity_X, angular_velocity_Y, angular_velocity_Z,
			linear_acceleration_X, linear_acceleration_Y, linear_acceleration_Z)

		dist_v <- sqrt(diff(this_chunk_df$linear_acceleration_X)^2 + diff(this_chunk_df$linear_acceleration_Y)^2 + diff(this_chunk_df$linear_acceleration_Z)^2)
		omega_v <- sqrt(diff(this_chunk_df$angular_velocity_X)^2 + diff(this_chunk_df$angular_velocity_Y)^2 + diff(this_chunk_df$angular_velocity_Z)^2)
		phi_v <- abs(diff(this_chunk_df$phi))
		theta_v <- abs(diff(this_chunk_df$theta))
		psi_v <- abs(diff(this_chunk_df$psi))

		# fill or temp data frame with summary computations for our 128 measurement set
		tmp_df <- bind_rows(tmp_df, data_frame(
			dist_total = sum(dist_v),
			dist_max = max(dist_v),
			dist_min = min(dist_v),
			dist_max_to_min = max(dist_v)/min(dist_v),
			dist_mean = mean(dist_v),
			dist_sd = sd(dist_v),
			dist_mean_to_sd = mean(dist_v)/sd(dist_v),  # reciprocal coef of variation
			
			omega_total = sum(omega_v),
			omega_max = max(omega_v),
			omega_min = min(omega_v),
			omega_max_to_min = max(omega_v)/min(omega_v),
			omega_mean = mean(omega_v),
			omega_sd = sd(omega_v),
			omega_mean_to_sd = mean(omega_v)/sd(omega_v), # reciprocal coef of variation

			phi_total = sum(phi_v),
			phi_max = max(phi_v),
			phi_min = min(phi_v),
			phi_mean = mean(phi_v),
			phi_sd = sd(phi_v),
			phi_mean_to_sd = mean(phi_v)/sd(phi_v),
			
			theta_total = sum(theta_v),
			theta_max = max(theta_v),
			theta_min = min(theta_v),
			theta_mean = mean(theta_v),
			theta_sd = sd(theta_v),
			theta_mean_to_sd = mean(theta_v)/sd(theta_v),
			
			psi_total = sum(psi_v),
			psi_max = max(psi_v),
			psi_min = min(psi_v),
			psi_mean = mean(psi_v),
			psi_sd = sd(psi_v),
			psi_mean_to_sd = mean(psi_v)/sd(psi_v),
			
			euler_total = sum(phi_v + theta_v + psi_v), 
			euler_max = max(phi_v + theta_v + psi_v),
			euler_min = min(phi_v + theta_v + psi_v),
			euler_mean = mean(phi_v + theta_v + psi_v),
			euler_sd = sd(phi_v + theta_v + psi_v),
			euler_mean_to_sd = mean(phi_v + theta_v + psi_v)/sd(phi_v + theta_v + psi_v)
			))
	
	} # end of for over series
	
	# add the summary computations to the data set of series
	processed_data_df <- bind_cols(processed_data_df, tmp_df)

	# return the proceessed data
	processed_data_df
}

```


```{r preprocess both train and test data and save}

# pre-process train and test data sets
tic("process train data")
x_train_processed <- pre_process(train_df)
toc()

tic("process test data")
x_test_processed <- pre_process(test_df)
toc()

# rejoin train data with the labels data set
x_train_processed <- x_train_processed %>% left_join(y_train, by = "series_id")

write_csv(x_train_processed, "data/x_train_processed.csv")
write_csv(x_test_processed, "data/x_test_processed.csv")
```

## Load Pre-processed Data and Train the Model

```{r load data and partition, echo=TRUE, message=FALSE, warning=FALSE}

x_train_processed <- read_csv("data/x_train_processed.csv")
x_test_processed <- read_csv("data/x_test_processed.csv")

# if we load data from a file, convert surface to factor
x_train_processed <- x_train_processed %>% mutate(surface = as.factor(surface))

# use a smaller set of datab to save time
x_train_processed <- x_train_processed # %>% slice(1:1000)

# remove series_id
# x_train_processed <- x_train_processed %>% select(-series_id)

# remove group_id
x_train_processed <- x_train_processed %>% select(-group_id)

# ##########################
# try diversee sets of features

# x_train_processed <- x_train_processed %>% select(surface, phi_mean_all, theta_mean_all, psi_mean_all,   dist_total, dist_sd,    dist_mean,  omega_total,    psi_total,    dist_mean_to_sd,   omega_mean,     psi_mean, psi_sd,  psi_mean_to_sd_all,     omega_sd, theta_mean_to_sd_all,     dist_max,     theta_sd, phi_mean_to_sd_all)

# used for last models
x_train_processed <- x_train_processed %>% select(series_id, surface, 
																									phi_mean_all, theta_mean_all, psi_mean_all, dist_total, omega_total, theta_total, psi_total, phi_sd, theta_sd, psi_sd, 
																									dist_mean_to_sd, omega_mean_to_sd)

x_test_processed <- x_test_processed  %>% select(series_id, 
																								phi_mean_all, theta_mean_all, psi_mean_all, dist_total, omega_total, theta_total, psi_total, phi_sd, theta_sd, psi_sd, 
																								dist_mean_to_sd, omega_mean_to_sd)



 # x_train_processed <- x_train_processed %>% select(-omega_max, -omega_sd, -omega_total, -omega_mean, -dist_mean, -dist_total, -dist_sd, -psi_sd, -theta_sd, -theta_total, -psi_total, -euler_mean_to_sd, -phi_min, -euler_sd, -psi_min, -phi_sd_all, -euler_max, -euler_total, -phi_total, -phi_mean)

# based on my intuition
# x_train_processed <- x_train_processed %>% select(surface,
# 																									dist_mean_to_sd,
# 																									omega_mean_to_sd,
# 																									euler_mean_to_sd,
# 																									
# 																									phi_mean_all, 
# 																									theta_mean_all, 
# 																									psi_mean_all)

# ##########################



# ##########################
# # use PCA
# pca <- prcomp(select(x_train_processed, -surface))
# summary(pca)
# x_train_processed <- data.frame(pca$x[,1:3]) %>% mutate(surface = x_train_processed$surface)
# ##########################


# partition data for training
test_index <- createDataPartition(y = x_train_processed$surface, times = 1, p = 0.5, list = FALSE)
x_train_for_train <- x_train_processed[-test_index, ]
x_train_for_test <- x_train_processed[test_index, ]

```


```{r}
# x_train_processed %>% filter(dist_total < 1)
# min(x_train_processed$dist_total)

# x_train_processed[which.min(x_train_processed$dist_total), ]
```



# Training Data Visualization


```{r, fig.width=16, fig.height=9, fig.retina=4}

x <- x_train_for_train %>% select(-surface) %>% as.matrix()
y <- x_train_for_train$surface

findCorrelation(cor(x), names = TRUE)

#####
# totals vs meean_to_sd

x_train_processed %>%  ggplot(aes(dist_total, dist_mean_to_sd, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)

x_train_processed %>%  ggplot(aes(omega_total, omega_mean_to_sd, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)

x_train_processed %>%  ggplot(aes(euler_total, euler_mean_to_sd, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)
```


```{r, fig.width=16, fig.height=9, fig.retina=4}

#####
# euler gyro angles
x_train_processed %>%  ggplot(aes(phi_mean_all, psi_mean_all, fill = surface)) +
	geom_point(aes(color = surface)) + 
	geom_point(cex=6, pch=21)

x_train_processed %>%  ggplot(aes(theta_mean_all, psi_mean_all, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)

x_train_processed %>%  ggplot(aes(theta_mean_all, phi_mean_all, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)

x_train_processed %>%  ggplot(aes(phi_mean_to_sd_all, psi_mean_to_sd_all, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)

x_train_processed %>%  ggplot(aes(phi_mean_to_sd_all, theta_mean_to_sd_all, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)

x_train_processed %>%  ggplot(aes(theta_mean_to_sd_all, psi_mean_to_sd_all, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)

x_train_processed %>%  ggplot(aes(dist_total, omega_total, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)

x_train_processed %>%  ggplot(aes(dist_total, phi_total + theta_total + psi_total, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)
```


```{r, fig.width=16, fig.height=9, fig.retina=4}

#####
# dist_mean_to_sd vs omega_mean_to_sd vs euler_mean_to_sd

x_train_processed %>%  ggplot(aes(euler_mean_to_sd, dist_mean_to_sd, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)

x_train_processed %>%  ggplot(aes(euler_mean_to_sd, omega_mean_to_sd, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)

x_train_processed %>%  ggplot(aes(dist_mean_to_sd, omega_mean_to_sd, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)

```


```{r, fig.width=16, fig.height=9, fig.retina=4}


#####
# dist_total vs omega_total vs euler_total, radius of dist to omega vs dist to omega angle
x_train_processed %>%  ggplot(aes(dist_total, theta_total, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)

x_train_processed %>%  ggplot(aes(dist_total, psi_total, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)

x_train_processed %>%  ggplot(aes(dist_total, omega_total, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)

x_train_processed %>%  ggplot(aes(dist_total, euler_total, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)

x_train_processed %>%  ggplot(aes(sqrt(dist_total^2 + omega_total^2), omega_total/dist_total, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)

x_train_processed %>%  ggplot(aes(sqrt(dist_total^2 + euler_total^2), euler_total/dist_total, fill = surface)) +
	geom_point(aes(color = surface))+
	geom_point(cex=6, pch=21)

```


```{r, fig.width=16, fig.height=9, fig.retina=4}
#####
# dist to sd of phi, theta psi
x_train_processed %>%  ggplot(aes(dist_total, phi_sd, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)

x_train_processed %>%  ggplot(aes(dist_total, theta_sd, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)

x_train_processed %>%  ggplot(aes(dist_total, psi_sd, fill = surface)) +
	geom_point(aes(color = surface)) +
	geom_point(cex=6, pch=21)

tmp <- x_train_processed %>% group_by(surface) %>% 
	summarize( omega_sd_of_mean_to_sd = sd(omega_mean_to_sd),
						 dist_sd_of_mean_to_sd = sd(dist_mean_to_sd)
					)

# x_train_processed %>% filter(surface == "soft_tiles")
```

# Test Data Visualization

```{r, fig.width=16, fig.height=9, fig.retina=4}
x_test_processed %>%  ggplot(aes(dist_total, theta_total, fill = surface)) +
	geom_point(aes(color = surface))

x_test_processed %>%  ggplot(aes(dist_total, psi_total, fill = surface)) +
	geom_point(aes(color = surface))

x_test_processed %>%  ggplot(aes(dist_total, euler_total, fill = surface)) +
	geom_point(aes(color = surface))

x_test_processed %>%  ggplot(aes(sqrt(dist_total^2 + omega_total^2), omega_total/dist_total, fill = surface)) +
	geom_point(aes(color = surface))

```



## KNN


```{r}

tic(" fit model knn")
fit <- train(surface ~ . ,  method = "knn", 
             tuneGrid = data.frame(k = seq(2, 100, 2)), 
             data = x_train_for_train)
toc()

ggplot(fit) 

# fit <- train(surface ~ ., method = "knn", data = x_train_for_test, k = 36)

fit$bestTune

y_hat <- predict(fit, x_train_for_test, type = "raw")
conf_matrix <- confusionMatrix(y_hat, x_train_for_test$surface)
conf_matrix$overall["Accuracy"]
conf_matrix$table
```

## RPart

```{r}
train_rpart <- train(surface ~ ., 
                     method = "rpart",
                     tuneGrid = data.frame(cp = seq(0, 0.075, len = 40)),
                     data = select(x_train_for_train, -series_id))
ggplot(train_rpart)

confusionMatrix(predict(train_rpart, x_train_for_test), x_train_for_test$surface)$overall["Accuracy"]
```

## Random Forest Untuned

```{r}

model_fit_RF_untuned <- randomForest(surface ~ ., data = select(x_train_for_train, -series_id))

y_hat <- predict(model_fit_RF_untuned, x_train_for_test)
y_test <- x_train_for_test$surface

sum(y_hat == y_test)/nrow(x_train_for_test)

conf_matrix <- confusionMatrix(y_hat, x_train_for_test$surface)
conf_matrix$overall["Accuracy"]
conf_matrix$table %>% knitr::kable()


# model_fit_RF_untuned <- randomForest(surface ~ ., data = x_train_processed)
# 
# # predict
# y_hat <- predict(model_fit_RF_untuned, select(x_test_processed, -series_id))
# 
# x_test_processed_for_submission <- x_test_processed %>% select(series_id) %>% mutate(surface = y_hat)
# write_csv(x_test_processed_for_submission, "data/submission_RF_untuned0_02.csv")

```
## Random Forest Caret Package

```{r}

model_fit_rf <- train(Class ~ ., data = training,
method = "rf",
metric = "ROC",
tuneGrid = data.frame(mtry = 3),
trControl = trainControl(method = "cv",
                        classProbs = TRUE,
                        summaryFunction = twoClassSummary))

```


## Random Forests Customized one-vs-one

```{r randomTrees, fig.height=9, fig.width = 16}
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")

metric <- "Accuracy"

mtry <- sqrt(ncol(x_train_for_train) - 1)
# mtry <- 2:5
tunegrid <- expand.grid(.mtry=mtry,.ntree=c(500, 1000, 1500, 2000, 2500) )

# tunegrid <- expand.grid(.mtry=c(1:10))

customRF 						<- 	list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- 	data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid 			<- 	function(x, y, len = NULL, search = "grid") {}
customRF$fit 				<- 	function(x, y, wts, param, lev, last, weights, classProbs, ...) randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
customRF$predict 		<- 	function(modelFit, newdata, preProc = NULL, submodels = NULL) predict(modelFit, newdata)
customRF$prob 			<- 	function(modelFit, newdata, preProc = NULL, submodels = NULL)	predict(modelFit, newdata, type = "prob")
customRF$sort 			<- 	function(x) x[order(x[,1]),]
customRF$levels 		<- 	function(x) x$surface


model_fit_rf <- train(surface ~ ., 
											data = select(x_train_for_train, -series_id), 
											method=customRF, 
											metric=metric, 
											tuneGrid=tunegrid, 
											trControl=control
											)
print(model_fit_rf)
plot(model_fit_rf)

y_hat <- predict(model_fit_rf, x_train_for_test)
y_test <- x_train_for_test$surface

importance <- importance(model_fit_rf$finalModel)
# importance[order(importance[,1], decreasing = TRUE), ]
# varImpPlot(model_fit_rf$finalModel)

conf_matrix <- confusionMatrix(y_hat, x_train_for_test$surface)
conf_matrix$overall["Accuracy"]
conf_matrix$table

# nzv <- nearZeroVar(x_train_for_train)
# nzv[,][1:10,]

# create the model using the whole train data 
# model_fit_rf <- train(surface~., data=x_train_processed, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)

# save the model
# saveRDS(model_fit_rf, file = "models/model_fit_RF_one_vs_one.rds")

# # save the model
# saveRDS(model_fit_rf, file = "models/model_RF_one_vs_one.rds")
# model_soft_pvc <- readRDS("models/model_RF_one_vs_one.rds")
# y_hat <- predict(model_soft_pvc, x_train_for_test)
# y_test <- x_train_for_test$surface
# print(sum(y_hat == y_test)/nrow(x_train_for_test))
```


## Produce Data For Submission

```{r}
# get just the series_id to be merged later with y_hat
test_series_id <- x_test_processed %>% select(series_id)

# remove series_id from the data set in order to make the predictions
x_test_processed_for_predict <- x_test_processed %>% select(-series_id)

# read the saved model
model_fit_RF <- readRDS("models/model_fit_RF_one_vs_one.rds")

# predict
y_hat <- predict(model_fit_RF, x_test_processed_for_predict)

# produce Kaggle data for submission

submission <- test_series_id %>% mutate(surface = y_hat)
write_csv(submission, "data/submission_02.csv")

```


## Create Models for One vs All Scenario

Here we will perform a binary classification for each of the class.
We will keep current surface and rename the rest of the surfaces to "the_rest".
Qw will save each modeel on a file on hard-disk

```{r one-vs-all}
# get a small chunk for now
x_train_processed_ova <- x_train_processed # %>% slice(1:1000)
x_train_processed_ova_initial <- x_train_processed_ova


# partition data into train and test, here we still use the train partition initially created
test_index <- createDataPartition(y = x_train_processed_ova$surface, times = 1, p = 0.5, list = FALSE)

x_train_for_train_ova <- x_train_processed_ova[-test_index, ]
x_train_for_test_ova <- x_train_processed_ova[test_index, ]

# save train and test sets in their initial state
x_train_for_train_ova_initial <- x_train_for_train_ova
x_train_for_test_ova_initial <- x_train_for_test_ova

# partition data into:train, test, and balancing pool
# we will use the pool to extract records to balance the dataset
# folds <- createFolds(x, k = 3, list = TRUE)

# get surfaces in a data frame, so we can loop over
surfaces <- x_train_for_train_ova %>% group_by(surface) %>% 
	summarize(n = n()) %>% 
	mutate(surface = as.character(surface)) %>% 
	# filter(surface == "hard_tiles") %>% 
	arrange(n)

for(current_surface in surfaces$surface)
{
		# convert surface to two values
		# x_train_for_train_ova_current <- x_train_for_train_ova %>% 
		# 	mutate(surface = ifelse(surface == current_surface, current_surface, "the_rest")) %>% 
		# 	mutate(surface = as.factor(surface))	
		
		# do training of full train data
		x_train_for_train_ova_current <- x_train_processed %>% 
			mutate(surface = ifelse(surface == current_surface, current_surface, "the_rest")) %>% 
			mutate(surface = as.factor(surface))
		
		mtry <- sqrt(ncol(x_train_for_train_ova_current) - 1)
		# mtry <- 2:5
		# mtry <- c(3.2, 3.4, 3.6, 3.8)
		# tunegrid <- expand.grid(.mtry=mtry,.ntree=c(500, 1000, 1500, 2000, 2500) )
		tunegrid <- expand.grid(.mtry=mtry,.ntree=c(100, 300, 400, 500, 1000, 1500, 2000))
		# metric <- "ROC"
		control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid", classProbs = TRUE, summaryFunction = twoClassSummary)
		
		model_fit_current <- train(surface ~ ., data = x_train_for_train_ova_current, method=customRF, metric="ROC", tuneGrid=tunegrid, trControl=control)
		
		# model_fit_current <- train(surface ~ ., data = x_train_for_train_ova_current,
		# 		method = "rf",
		# 		metric = "ROC",
		# 		tuneGrid = data.frame(mtry = mtry),
		# 		trControl = trainControl(method = "cv",
		# 		                        classProbs = TRUE,
		# 		                        summaryFunction = twoClassSummary))
		# 
		# assign(model_name, model_fit_current)
		print(model_fit_current)
		# plot(model_fit_current)
		
		
		y_hat <- predict(model_fit_current, x_train_for_test_ova_current, type = "raw")
		y_hat_prob <- predict(model_fit_current, x_train_for_test_ova_current, type = "prob")
		
		model_name <- paste("model_02_fit_rf_", current_surface, sep = "")
		file <- paste("models/",  model_name, ".rds", sep = "")
		write_rds(model_fit_current, file)
}


```


## Load Models and Perform the Prediction

Loop over each surface, load the model from hard-disk and perform the prediction.


```{r}


# get surfaces in a data frame, so we can loop over
surfaces <- x_train_for_train_ova %>% group_by(surface) %>% 
	summarize(n = n()) %>% 
	mutate(surface = as.character(surface)) %>% 
	arrange(n)

# store final result in this table
results_df <- data.frame(surface = "Surface", model_name = "Model Name", ova_accuracy = "One-vs-All Accuracy")

# create a data frame that will store the results from each model
# set it up with series_id and true_surface initially, i'll usee this one mostly for pre-viewing the data
results <- data.frame(
	series_id = x_train_for_test_ova$series_id, 
	true_surface = x_train_for_test_ova$surface)

# results <- results %>% mutate(rowNum = row_number()) 

# create a data frame the will store probabilities for each model
# we'll use this for voting
# the model with highes prediction will get the vote

results_voting <- data.frame(
	series_id = x_train_for_test_ova$series_id, 
	true_surface = x_train_for_test_ova$surface)

# filter for a surface of interest
# surfaces <- surfaces %>% filter(surface == "hard_tiles")
# surfaces <- surfaces %>% filter(surface == "concrete")

for(current_surface in surfaces$surface){
	
	# prepare the test dataset
	x_train_for_test_ova_current <- x_train_for_test_ova %>% 
			mutate(surface = ifelse(surface == current_surface, current_surface, "the_rest")) %>% 
			mutate(surface = as.factor(surface))
	
	# get the modeel from a file
	model_name <- paste("model_fit_rf_", current_surface, sep = "")
	model_fit_current <- readRDS(paste("models/", model_name, ".rds", sep = ""))
	
	# get y_hat and y_hat_prob
	y_hat <- predict(model_fit_current, x_train_for_test_ova_current, type = "raw")
	y_hat_prob <- predict(model_fit_current, x_train_for_test_ova_current, type = "prob")
	
	# get the y_test
	y_test <-  x_train_for_test_ova_current$surface
	
	# store results
	results <- results %>% mutate(last_result = y_hat)
	names(results)[ncol(results)] <- paste(current_surface, "_pred", sep = "")
	
	# store the results as probability of the minority class. that is our surface
	results <- results %>% mutate(last_result_prob = y_hat_prob[,current_surface])
	names(results)[ncol(results)] <- paste(current_surface, "_prob", sep = "")
	
	# store the probability of curent model for current surface in a column named by current surface
	results_voting <- results_voting %>% mutate(last_result_prob = y_hat_prob[,current_surface])
	names(results_voting)[ncol(results_voting)] <- current_surface # the column name is current surface
	
	# compute confusion matrix and print it
	conf_matrix <- confusionMatrix(y_hat, x_train_for_test_ova_current$surface)
	print(conf_matrix$overall["Accuracy"])
	print(conf_matrix$table)

		# store accuracy
	results_df <- results_df %>% bind_rows(data.frame(surface = current_surface, model_name = model_name, ova_accuracy = as.character(conf_matrix$overall["Accuracy"] )))
	
}

results


# analyse some cases
results %>% filter(series_id == 66)

# sum(results[,6] == "the_rest")
# 
# results %>%  knitr::kable() %>% 
# 	kable_styling(full_width = F)
# 
# results_df %>% knitr::kable()

# y_hat_hard_tiles <- y_hat
# sum(y_hat[,1] >= 0.2)
```



## Create Final Prediction Based on Voting

```{r}
results_voting
results_voting[4,]

results_voting <- results_voting %>%  mutate(pred_surface = rep("", nrow(results_voting)))

for (i in 1:nrow(results_voting)) {
		results_voting[i, "pred_surface"] <- names(which.max(select(results_voting[i,], -series_id, -true_surface, -pred_surface)))
}

results_voting <- results_voting %>% mutate(pred_surface = as.factor(pred_surface))

sum(results_voting[, "true_surface"] == results_voting[, "pred_surface"])/nrow(results_voting)
```




## Evaluate Test Dataset and Submit

```{r}

# get surfaces in a data frame, so we can loop over
surfaces <- x_train_for_train_ova %>% group_by(surface) %>% 
	summarize(n = n()) %>% 
	mutate(surface = as.character(surface)) %>% 
	arrange(n)

# create a data frame the will store probabilities for each model
# we'll use this for voting
# the model with highes prediction will get the vote
results_voting <- data.frame(
	series_id = x_test_processed$series_id)


for(current_surface in surfaces$surface){
	
	# get the model from a file
	model_name <- paste("model_fit_rf_", current_surface, sep = "")
	model_fit_current <- readRDS(paste("models/", model_name, ".rds", sep = ""))
	
	# get y_hat and y_hat_prob
	y_hat <- predict(model_fit_current, x_test_processed, type = "raw")
	y_hat_prob <- predict(model_fit_current, x_test_processed, type = "prob")

	# store the probability of curent model for current surface in a column named by current surface
	results_voting <- results_voting %>% mutate(last_result_prob = y_hat_prob[,current_surface])
	names(results_voting)[ncol(results_voting)] <- current_surface # the column name is current surface
	
}

# results_voting
results_voting <- results_voting %>%  mutate(surface = rep("", nrow(results_voting)))

for (i in 1:nrow(results_voting)) {
		results_voting[i, "surface"] <- names(which.max(select(results_voting[i,], -series_id, -surface)))
}

results_voting <- results_voting %>% mutate(surface = as.factor(surface))

submission <- results_voting %>% select(series_id, surface)
write_csv(submission, "data/submission_04.csv")
```


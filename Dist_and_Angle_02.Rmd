---
title: "Surface Detection by Robot Movements"
author: "Marian Dumitrascu"
date: "March 19, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Surface Detection by Robot Movements


## Introduction

gyros, accelerometer and magnetometer sensor

## Data Analysis

You can include R code in the document as follows:

```{r data load, message=FALSE, warning=FALSE}
# install.packages("ISLR")
# install.packages("orientlib")
# install.packages("RSpincalc")
# devtools::install_github("collectivemedia/tictoc")
library(readr)
library(tidyverse)
library(ISLR)
library(caret)
library(orientlib)
library(matrixStats)
library(randomForest)
library(RSpincalc)
library(tictoc)


x_train <- read_csv("data/X_train.csv")
y_train <- read_csv("data/y_train.csv")
x_test <- read_csv("data/x_test.csv")
```
```{r}

# nrow(x_test)/128

```


```{r data analysis}

# join the labels with the training data set
train_set <- x_train %>% left_join(y_train, by = "series_id")
train_df <- as.data.frame(train_set)
test_df <- as.data.frame(x_test)

train_df <- mutate(train_df, surface = as.factor(surface)) %>% 
	select(-group_id)

```

```{r}

convert_quaternions_to_euler <- function(a_dataset){
	# use Q2EA from RSpincalc to convert quaternions to euler angles
	Q <- a_dataset %>% select(orientation_X, orientation_Y, orientation_Z, orientation_W) %>% as.matrix()
	euler_matrix <- Q2EA(Q, EulerOrder='xyz', tol = 10 * .Machine$double.eps, ichk = FALSE, ignoreAllChk = FALSE)

	# add the new columns to the dataset
	a_dataset <- a_dataset %>% mutate(phi = euler_matrix[,1], theta = euler_matrix[,2], psi = euler_matrix[,3])
	
	# remove quaternion columns
	a_dataset <- a_dataset %>% select(-orientation_X, -orientation_Y,  -orientation_Z, -orientation_W)
	
	# return the new dataset
	a_dataset
}

train_df <- convert_quaternions_to_euler(train_df)
test_df <- convert_quaternions_to_euler(test_df)


```



```{r}
# function for prreprocessing 
# n_of_rows defaults to total number ofseries
# is_train indicates that the data is training, thus will do an extra action
pre_process <- function(a_dataframe, n_of_rows = nrow(a_dataframe)/128 ) {
	
	# get data grouped by seeries_id and compute some means 
	processed_data_df <- a_dataframe %>% 
	group_by(series_id) %>% 
	summarize(
		phi_mean_all = mean(phi),
		phi_sd_all = sd(phi),
		phi_mean_to_sd_all = mean(phi)/sd(phi),
		theta_mean_all = mean(theta),
		theta_sd_all = sd(theta),
		theta_mean_to_sd_all = mean(theta)/sd(theta),
		psi_mean_all = mean(psi),
		psi_sd_all = sd(psi),
		psi_mean_to_sd_all = mean(psi)/sd(psi)
		) %>% 
		slice(1:n_of_rows)
	
	# define an empty data frame with summary metrics that we'll use for each set of 128 observations
	metrics <- c("dist_total","dist_max","dist_min","dist_max_to_min","dist_mean","dist_sd","dist_mean_to_sd",
							 "omega_total","omega_max","omega_min","omega_max_to_min","omega_mean","omega_sd","omega_mean_to_sd",
							 "phi_total","phi_max","phi_min","phi_mean","phi_sd","phi_mean_to_sd",
							 "theta_total","theta_max","theta_min","theta_mean","theta_sd","theta_mean_to_sd",
							 "psi_total","psi_max","psi_min","psi_mean","psi_sd","psi_mean_to_sd",
							 "euler_total","euler_max","euler_min","euler_mean","euler_sd","euler_mean_to_sd")
	tmp_df <- data.frame(matrix(ncol = length(metrics), nrow = 0) )
	colnames(tmp_df) <- metrics

	# loop over each series
	# should use apply type of function here, but I use "for" until I master the apply
	for (s_id in processed_data_df$series_id)
	{
		# get current measurement set
		this_chunk_df <- a_dataframe %>% filter(series_id == s_id)
		
		# select only columns we are interested in 
		this_chunk_df <- this_chunk_df %>% 
			select(
			phi, theta, psi,  
			angular_velocity_X, angular_velocity_Y, angular_velocity_Z,
			linear_acceleration_X, linear_acceleration_Y, linear_acceleration_Z)

		dist_v <- sqrt(diff(this_chunk_df$linear_acceleration_X)^2 + diff(this_chunk_df$linear_acceleration_Y)^2 + diff(this_chunk_df$linear_acceleration_Z)^2)
		omega_v <- sqrt(diff(this_chunk_df$angular_velocity_X)^2 + diff(this_chunk_df$angular_velocity_Y)^2 + diff(this_chunk_df$angular_velocity_Z)^2)
		phi_v <- abs(diff(this_chunk_df$phi))
		theta_v <- abs(diff(this_chunk_df$theta))
		psi_v <- abs(diff(this_chunk_df$psi))

		# fill or temp data frame with summary computations for our 128 measurement set
		tmp_df <- bind_rows(tmp_df, data_frame(
			dist_total = sum(dist_v),
			dist_max = max(dist_v),
			dist_min = min(dist_v),
			dist_max_to_min = max(dist_v)/min(dist_v),
			dist_mean = mean(dist_v),
			dist_sd = sd(dist_v),
			dist_mean_to_sd = mean(dist_v)/sd(dist_v),  # reciprocal coef of variation
			
			omega_total = sum(omega_v),
			omega_max = max(omega_v),
			omega_min = min(omega_v),
			omega_max_to_min = max(omega_v)/min(omega_v),
			omega_mean = mean(omega_v),
			omega_sd = sd(omega_v),
			omega_mean_to_sd = mean(omega_v)/sd(omega_v), # reciprocal coef of variation

			phi_total = sum(phi_v),
			phi_max = max(phi_v),
			phi_min = min(phi_v),
			phi_mean = mean(phi_v),
			phi_sd = sd(phi_v),
			phi_mean_to_sd = mean(phi_v)/sd(phi_v),
			
			theta_total = sum(theta_v),
			theta_max = max(theta_v),
			theta_min = min(theta_v),
			theta_mean = mean(theta_v),
			theta_sd = sd(theta_v),
			theta_mean_to_sd = mean(theta_v)/sd(theta_v),
			
			psi_total = sum(psi_v),
			psi_max = max(psi_v),
			psi_min = min(psi_v),
			psi_mean = mean(psi_v),
			psi_sd = sd(psi_v),
			psi_mean_to_sd = mean(psi_v)/sd(psi_v),
			
			euler_total = sum(phi_v + theta_v + psi_v), 
			euler_max = max(phi_v + theta_v + psi_v),
			euler_min = min(phi_v + theta_v + psi_v),
			euler_mean = mean(phi_v + theta_v + psi_v),
			euler_sd = sd(phi_v + theta_v + psi_v),
			euler_mean_to_sd = mean(phi_v + theta_v + psi_v)/sd(phi_v + theta_v + psi_v)
			))
	
	} # end of for over series
	
	# add the summary computations to the data set of series
	processed_data_df <- bind_cols(processed_data_df, tmp_df)

	# return the proceessed data
	processed_data_df
}

```


```{r preprocess both train and test data and save}

# pre-process train and test data sets
tic("process train data")
x_train_processed <- pre_process(train_df)
toc()

tic("process test data")
x_test_processed <- pre_process(test_df)
toc()

# rejoin train data with the labels data set
x_train_processed <- x_train_processed %>% left_join(y_train, by = "series_id")

write_csv(x_train_processed, "data/x_train_processed.csv")
write_csv(x_test_processed, "data/x_test_processed.csv")
```


```{r load data and partition, echo=TRUE, message=FALSE, warning=FALSE}

x_train_processed <- read_csv("data/x_train_processed.csv")
x_test_processed <- read_csv("data/x_test_processed.csv")

# if we load data from a file, convert surface to factor
x_train_processed <- x_train_processed %>% mutate(surface = as.factor(surface))

# use a smaller set of datab to save time
x_train_processed <- x_train_processed %>% slice(1:2000)

# remove series_id
x_train_processed <- x_train_processed %>% select(-series_id)

# remove group_id
x_train_processed <- x_train_processed %>% select(-group_id)

# ##########################
# try diversee sets of features

# x_train_processed <- x_train_processed %>% select(surface, phi_mean_all, theta_mean_all, psi_mean_all,   dist_total, dist_sd,    dist_mean,  omega_total,    psi_total,    dist_mean_to_sd,   omega_mean,     psi_mean, psi_sd,  psi_mean_to_sd_all,     omega_sd, theta_mean_to_sd_all,     dist_max,     theta_sd, phi_mean_to_sd_all)

# x_train_processed <- x_train_processed %>% select(surface, phi_mean_all, theta_mean_all, psi_mean_all, dist_total, omega_total, theta_total, psi_total)

# x_train_processed <- x_train_processed %>% select(-omega_max, -omega_sd, -omega_total, -omega_mean, -dist_mean, -dist_total, -dist_sd, -psi_sd, -theta_sd, -theta_total, -psi_total, -euler_mean_to_sd, -phi_min, -euler_sd, -psi_min, -phi_sd_all, -euler_max, -euler_total, -phi_total, -phi_mean)

# based on my intuition
x_train_processed <- x_train_processed %>% select(surface,
																									dist_mean_to_sd,
																									omega_mean_to_sd,
																									euler_mean_to_sd,
																									
																									phi_mean_all, 
																									theta_mean_all, 
																									psi_mean_all)

# ##########################



# ##########################
# # use PCA
# pca <- prcomp(select(x_train_processed, -surface))
# summary(pca)
# x_train_processed <- data.frame(pca$x[,1:3]) %>% mutate(surface = x_train_processed$surface)
# ##########################


# partition data for training
test_index <- createDataPartition(y = x_train_processed$surface, times = 1, p = 0.5, list = FALSE)
x_train_for_train <- x_train_processed[-test_index, ]
x_train_for_test <- x_train_processed[test_index, ]

```


# Data Visualization


```{r, fig.width=16, fig.height=9, fig.retina=4}

x <- x_train_for_train %>% select(-surface) %>% as.matrix()
y <- x_train_for_train$surface

findCorrelation(cor(x), names = TRUE)

x_train_processed %>%  ggplot(aes(dist_total, dist_mean_to_sd, fill = surface)) +
	geom_point(aes(color = surface))

x_train_processed %>%  ggplot(aes(omega_total, omega_mean_to_sd, fill = surface)) +
	geom_point(aes(color = surface))

x_train_processed %>%  ggplot(aes(euler_total, euler_mean_to_sd, fill = surface)) +
	geom_point(aes(color = surface))

x_train_processed %>%  ggplot(aes(phi_mean_all, psi_mean_all, fill = surface)) +
	geom_point(aes(color = surface))

x_train_processed %>%  ggplot(aes(theta_mean_all, psi_mean_all, fill = surface)) +
	geom_point(aes(color = surface))

x_train_processed %>%  ggplot(aes(theta_mean_all, phi_mean_all, fill = surface)) +
	geom_point(aes(color = surface))

x_train_processed %>%  ggplot(aes(phi_mean_to_sd_all, psi_mean_to_sd_all, fill = surface)) +
	geom_point(aes(color = surface))

x_train_processed %>%  ggplot(aes(phi_mean_to_sd_all, theta_mean_to_sd_all, fill = surface)) +
	geom_point(aes(color = surface))

x_train_processed %>%  ggplot(aes(theta_mean_to_sd_all, psi_mean_to_sd_all, fill = surface)) +
	geom_point(aes(color = surface))

x_train_processed %>%  ggplot(aes(dist_total, omega_total, fill = surface)) +
	geom_point(aes(color = surface))

x_train_processed %>%  ggplot(aes(dist_total, phi_total + theta_total + psi_total, fill = surface)) +
	geom_point(aes(color = surface))




x_train_processed %>%  ggplot(aes(euler_mean_to_sd, dist_mean_to_sd, fill = surface)) +
	geom_point(aes(color = surface))

x_train_processed %>%  ggplot(aes(euler_mean_to_sd, omega_mean_to_sd, fill = surface)) +
	geom_point(aes(color = surface))

x_train_processed %>%  ggplot(aes(dist_mean_to_sd, omega_mean_to_sd, fill = surface)) +
	geom_point(aes(color = surface))





x_train_processed %>%  ggplot(aes(dist_total, theta_total, fill = surface)) +
	geom_point(aes(color = surface))

x_train_processed %>%  ggplot(aes(dist_total, psi_total, fill = surface)) +
	geom_point(aes(color = surface))

x_train_processed %>%  ggplot(aes(dist_total, omega_total, fill = surface)) +
	geom_point(aes(color = surface))

x_train_processed %>%  ggplot(aes(dist_total, euler_total, fill = surface)) +
	geom_point(aes(color = surface))

x_train_processed %>%  ggplot(aes(sqrt(dist_total^2 + omega_total^2), omega_total/dist_total, fill = surface)) +
	geom_point(aes(color = surface))

x_train_processed %>%  ggplot(aes(sqrt(dist_total^2 + euler_total^2), euler_total/dist_total, fill = surface)) +
	geom_point(aes(color = surface))

tmp <- x_train_processed %>% group_by(surface) %>% 
	summarize( omega_sd_of_mean_to_sd = sd(omega_mean_to_sd),
						 dist_sd_of_mean_to_sd = sd(dist_mean_to_sd)
					)

# x_train_processed %>% filter(surface == "soft_tiles")
```

```{r, fig.width=16, fig.height=9, fig.retina=4}
x_test_processed %>%  ggplot(aes(dist_total, theta_total, fill = surface)) +
	geom_point(aes(color = surface))

x_test_processed %>%  ggplot(aes(dist_total, psi_total, fill = surface)) +
	geom_point(aes(color = surface))

x_test_processed %>%  ggplot(aes(dist_total, euler_total, fill = surface)) +
	geom_point(aes(color = surface))

x_test_processed %>%  ggplot(aes(sqrt(dist_total^2 + omega_total^2), omega_total/dist_total, fill = surface)) +
	geom_point(aes(color = surface))

```




```{r}
x_train_processed %>%  ggplot(aes(PC2, PC3, fill = surface)) +
	geom_point(aes(color = surface))
```

```{r}

tic(" fit model knn")
fit <- train(surface ~ . ,  method = "knn", 
             tuneGrid = data.frame(k = seq(2, 100, 2)), 
             data = x_train_for_train)
toc()

ggplot(fit) 

# fit <- train(surface ~ ., method = "knn", data = x_train_for_test, k = 36)

fit$bestTune

y_hat <- predict(fit, x_train_for_test, type = "raw")
conf_matrix <- confusionMatrix(y_hat, x_train_for_test$surface)
conf_matrix$overall["Accuracy"]
conf_matrix$table
```

```{r}
train_rpart <- train(surface ~ ., 
                     method = "rpart",
                     tuneGrid = data.frame(cp = seq(0, 0.075, len = 40)),
                     data = x_train_for_train)
ggplot(train_rpart)

confusionMatrix(predict(train_rpart, x_train_for_test), x_train_for_test$surface)$overall["Accuracy"]
```


```{r}

fit_model_RF_untuned <- randomForest(surface ~ ., data = x_train_for_train) 
y_hat <- predict(fit_model_RF_untuned, x_train_for_test)
y_test <- x_train_for_test$surface

sum(y_hat == y_test)/nrow(x_train_for_test)

conf_matrix <- confusionMatrix(y_hat, x_train_for_test$surface)
conf_matrix$overall["Accuracy"]
conf_matrix$table %>% knitr::kable()






# fit_model_RF_untuned <- randomForest(surface ~ ., data = x_train_processed)
# 
# # predict
# y_hat <- predict(fit_model_RF_untuned, select(x_test_processed, -series_id))
# 
# x_test_processed_for_submission <- x_test_processed %>% select(series_id) %>% mutate(surface = y_hat)
# write_csv(x_test_processed_for_submission, "data/submission_RF_untuned0_02.csv")

```

```{r randomTrees, fig.height=9, fig.width = 16}
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")

metric <- "Accuracy"

mtry <- sqrt(ncol(x_train_for_train) - 1)
# mtry <- 2:5
tunegrid <- expand.grid(.mtry=mtry,.ntree=c(500, 1000, 1500, 2000, 2500) )

# tunegrid <- expand.grid(.mtry=c(1:10))

customRF 				<- 	list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters 	<- 	data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid 			<- 	function(x, y, len = NULL, search = "grid") {}
customRF$fit 			<- 	function(x, y, wts, param, lev, last, weights, classProbs, ...) randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
customRF$predict 		<- 	function(modelFit, newdata, preProc = NULL, submodels = NULL) predict(modelFit, newdata)
customRF$prob 			<- 	function(modelFit, newdata, preProc = NULL, submodels = NULL)	predict(modelFit, newdata, type = "prob")
customRF$sort 			<- 	function(x) x[order(x[,1]),]
customRF$levels 		<- 	function(x) x$surface


fit_model_rf <- train(surface~., data=x_train_for_train, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control, tuneLength = 15)
print(fit_model_rf)
plot(fit_model_rf)

y_hat <- predict(fit_model_rf, x_train_for_test)
y_test <- x_train_for_test$surface

importance <- importance(fit_model_rf$finalModel)
# importance[order(importance[,1], decreasing = TRUE), ]
# varImpPlot(fit_model_rf$finalModel)

conf_matrix <- confusionMatrix(y_hat, x_train_for_test$surface)
conf_matrix$overall["Accuracy"]
conf_matrix$table

# nzv <- nearZeroVar(x_train_for_train)
# nzv[,][1:10,]

# create the model using the whole train data 
# fit_model_rf <- train(surface~., data=x_train_processed, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)

# save the model
# saveRDS(fit_model_rf, file = "models/fit_model_RF_one_vs_one.rds")

# # save the model
# saveRDS(fit_model_rf, file = "models/model_RF_one_vs_one.rds")
# model_soft_pvc <- readRDS("models/model_RF_one_vs_one.rds")
# y_hat <- predict(model_soft_pvc, x_train_for_test)
# y_test <- x_train_for_test$surface
# print(sum(y_hat == y_test)/nrow(x_train_for_test))
```









```{r}
# get just the series_id to be merged later with y_hat
test_series_id <- x_test_processed %>% select(series_id)

# remove series_id from the data set in order to make the predictions
x_test_processed_for_predict <- x_test_processed %>% select(-series_id)

# read the saved model
fit_model_RF <- readRDS("models/fit_model_RF_one_vs_one.rds")

# predict
y_hat <- predict(fit_model_RF, x_test_processed_for_predict)

# produce Kaggle data for submission

submission <- test_series_id %>% mutate(surface = y_hat)
write_csv(submission, "data/submission_02.csv")

```



```{r one-vs-all}
# store results in this table
results_df <- data.frame(surface = "Surface", model_name = "Model Name", ova_accuracy = "One-vs-All Accuracy")

# get a small chunk for now
x_train_processed_ova <- x_train_processed %>% slice(1:1000)
x_train_processed_ova_initial <- x_train_processed_ova


# partition data into train and test
test_index <- createDataPartition(y = x_train_processed_ova$surface, times = 1, p = 0.5, list = FALSE)

x_train_for_train_ova <- x_train_processed_ova[-test_index, ]
x_train_for_test_ova <- x_train_processed_ova[test_index, ]

# save train and test sets in their initial state
x_train_for_train_ova_initial <- x_train_for_train_ova
x_train_for_test_ova_initial <- x_train_for_test_ova

## begin the loop
current_surface <- "wood"
surfaces <- x_train_for_train_ova %>% group_by(surface) %>% 
	summarize(n = n()) %>% 
	mutate(surface = as.character(surface)) %>% 
	arrange(n)

for(current_surface in surfaces$surface)
{
		# convert surface to two values
		x_train_for_train_ova_current <- x_train_for_train_ova %>% 
			mutate(surface = ifelse(surface == current_surface, current_surface, "the_rest")) %>% 
			mutate(surface = as.factor(surface))	
		
		# do the same for test
		x_train_for_test_ova_current <- x_train_for_test_ova %>% 
			mutate(surface = ifelse(surface == current_surface, current_surface, "the_rest")) %>% 
			mutate(surface = as.factor(surface))
		
		model_name <- paste("fit_model_rf_", current_surface, sep = "")
		
		mtry <- sqrt(ncol(x_train_for_train_ova_current) - 1)
		# tunegrid <- expand.grid(.mtry=mtry,.ntree=c(500, 1000, 1500, 2000, 2500) )
		tunegrid <- expand.grid(.mtry=mtry,.ntree=c(100, 300, 400))
		
		fit_model_current <- train(surface ~ ., data = x_train_for_train_ova_current, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
		assign(model_name, fit_model_current)
		print(fit_model_current)
		plot(fit_model_current)
		
		
		y_hat <- predict(fit_model_current, x_train_for_test_ova_current)
		y_test <-  x_train_for_test_ova_current$surface
		
		conf_matrix <- confusionMatrix(y_hat, x_train_for_test_ova_current$surface)
		conf_matrix$overall["Accuracy"]
		conf_matrix$table
		
		file <- paste("models/",  model_name, ".rds", sep = "")
		write_rds(fit_model_current, file)
		
		results_df <- results_df %>% bind_rows(data.frame(surface = current_surface, model_name = model_name, ova_accuracy = as.character(conf_matrix$overall["Accuracy"] )))
		results_df %>% knitr::kable()
}

results_df %>% knitr::kable()





```